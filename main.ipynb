{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hand Written Digit Recognition using MNIST Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required tools\n",
    "import numpy as np\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Keras utilities\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#import dataSet\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence of step for design of model and Evaluation\n",
    "1. Loading of the dataset\n",
    "2. Preparation of dataset\n",
    "3. Defining Model\n",
    "4. Evaluation of Model\n",
    "5. Presentation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for loading dataset\n",
    "def load_dataset():\n",
    "    (trainX,trainY),(testX,testY)=mnist.load_data()\n",
    "    #Reshaping dataset\n",
    "    trainX=trainX.reshape((trainX.shape[0],28,28,1))\n",
    "    testX=testX.reshape((testX.shape[0],28,28,1))\n",
    "    #one_hot encoding of labels\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(trainY)\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to prepare dataset\n",
    "def prep_dataset(train, test):\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    train_norm = train_norm/255.0\n",
    "    test_norm = test_norm/255.0\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Model\n",
    "def def_model():\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(100, activation='relu', kernel_initializer='he_uniform'),\n",
    "            Dense(10, activation='softmax')\n",
    "        ]\n",
    "    )\n",
    "    opt = SGD(learning_rate=0.01, momentum=0.9) #Stochastic grad. desc.\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the evaluation we can use the k fold cross validation taking k=5 such that each test set will be approx 20%\n",
    "of the total input dataset.K=5 is chosen so as to rather not be too large or be too big to take up a lot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of Model\n",
    "def eval_model(dataX, dataY, n_fold=5):\n",
    "    scores, histories = list(), list()\n",
    "    kfold = KFold(n_fold, shuffle=True, random_state=1)\n",
    "    \n",
    "    #enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(dataX):\n",
    "        model = def_model()\n",
    "        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "        history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "        _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "        print('>%.3f' %(acc*100.0))\n",
    "        scores.append(acc)\n",
    "        histories.append(history)\n",
    "    return scores, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for analysis of results\n",
    "def analyze(histories):\n",
    "    for i in range(len(histories)):\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.title('Cross Entropy Loss')\n",
    "        plt.plot(histories[i].history['loss'],color='blue',label='train')\n",
    "        plt.plot(histories[i].history['val_loss'],color='orange',label='test')\n",
    "                \n",
    "        plt.subplot(2,1,2)\n",
    "        plt.title('Classification Accuracy')\n",
    "        plt.plot(histories[i].history['accuracy'],color='blue',label='train')\n",
    "        plt.plot(histories[i].history['val_accuracy'],color='orange',label='test')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarizing the performance\n",
    "def summary(scores):\n",
    "    print(\"accuracy: mean=%.3f std=%.3f,n=%d\" %(np.mean(scores)*100,np.std(scores)*100,len(scores)))\n",
    "    plt.boxplot(scores)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#finalizing by calling all the functions\n",
    "def run():\n",
    "    trainx,trainy,testx,testy=load_dataset()\n",
    "    trainx,testx=prep_dataset(trainx,testx)\n",
    "    scores,histories=eval_model(trainx,trainy)\n",
    "    analyze(histories)\n",
    "    summary(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000, 10) (10000, 28, 28, 1) (60000, 10, 2)\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}